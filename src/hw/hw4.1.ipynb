{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ccdcfbc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "from typing import Dict, Any, List\n",
    "from pprint import pprint\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.tools import tool\n",
    "from langchain_core.messages import HumanMessage, ToolMessage, AIMessage\n",
    "from langchain_core.documents import Document\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_upstage import UpstageEmbeddings\n",
    "\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_community.utilities import WikipediaAPIWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a38b996c",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "TAVILY_API_KEY = os.getenv(\"TAVILY_API_KEY\")\n",
    "\n",
    "DATA_PATH = Path(\"./data/cafe_menu.txt\")\n",
    "DB_PATH = Path(\"./db/cafe_db\")\n",
    "DB_PATH.parent.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d1488466",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not DATA_PATH.exists():\n",
    "    raise FileNotFoundError(f\"{DATA_PATH} íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ./data/ ê²½ë¡œë¥¼ í™•ì¸í•˜ì„¸ìš”.\")\n",
    "\n",
    "file_content = DATA_PATH.read_text(encoding=\"utf-8\")\n",
    "\n",
    "# ë©”ë‰´ í•­ëª©ì€ ë¹ˆ ì¤„(\\n\\n)ë¡œ êµ¬ë¶„ë˜ì–´ ìˆë‹¤ê³  ê°€ì •\n",
    "menu_items = [blk.strip() for blk in file_content.strip().split(\"\\n\\n\") if blk.strip()]\n",
    "\n",
    "# ì›ë¬¸ ë‹¨ë½ ìì²´ë¥¼ ë¬¸ì„œí™”(ê°„ë‹¨í•˜ê²Œ ìœ ì§€)\n",
    "docs = [Document(page_content=item, metadata={\"source\": \"cafe_menu\"}) for item in menu_items]\n",
    "\n",
    "# í•„ìš” ì‹œ ë¬¸ì¥ ê¸¸ì´ ë³´ì •ì„ ìœ„í•´ ê°„ë‹¨ split (ì„ íƒ)\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=700, chunk_overlap=0)\n",
    "docs = splitter.split_documents(docs)\n",
    "\n",
    "upstage_key = os.getenv(\"UPSTAGE_API_KEY\")\n",
    "if not upstage_key:\n",
    "    raise RuntimeError(\"UPSTAGE_API_KEYê°€ í•„ìš”í•©ë‹ˆë‹¤ (.env í™•ì¸).\")\n",
    "embeddings = UpstageEmbeddings(model=\"solar-embedding-1-large\", api_key=upstage_key)\n",
    "db = FAISS.from_documents(docs, embeddings)\n",
    "db.save_local(str(DB_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "35d250ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ì§ˆë¬¸] ì•„ë©”ë¦¬ì¹´ë…¸ì˜ ê°€ê²©ê³¼ íŠ¹ì§•ì€ ë¬´ì—‡ì¸ê°€ìš”?\n",
      "[ë‹µë³€] ì•„ë©”ë¦¬ì¹´ë…¸ëŠ” **ì—ìŠ¤í”„ë ˆì†Œì— ëœ¨ê±°ìš´ ë¬¼ì„ ë”í•´ ë§Œë“  ì»¤í”¼**ë¡œ, **ì§„í•œ ì»¤í”¼ ë§›**ê³¼ **ê°„ë‹¨í•œ êµ¬ì„±**ì´ íŠ¹ì§•ì…ë‹ˆë‹¤.\n",
      "\n",
      "---\n",
      "\n",
      "### âœ… **íŠ¹ì§•**\n",
      "| í•­ëª© | ì„¤ëª… |\n",
      "|------|------|\n",
      "| **ë§›** | ì—ìŠ¤í”„ë ˆì†Œì˜ ì§„í•œ ë§›ì´ ëŠê»´ì§€ì§€ë§Œ, ë¬¼ë¡œ í¬ì„ë¼ **ì“´ë§›ì´ ê°•í•œ í¸**ì…ë‹ˆë‹¤. |\n",
      "| **ì¹¼ë¡œë¦¬** | **0kcal** (ì„¤íƒ•, ì‹œëŸ½ ì—†ì´ ë§ˆì‹¤ ê²½ìš°) |\n",
      "| **ì¹´í˜ì¸** | ë³´í†µ **1ìƒ·(75~100mg)** ê¸°ì¤€, 2ìƒ·ë„ ê°€ëŠ¥ |\n",
      "| **êµ¬ì„±** | ì—ìŠ¤í”„ë ˆì†Œ + ëœ¨ê±°ìš´ ë¬¼ (ìš°ìœ , ì„¤íƒ• ì—†ìŒ) |\n",
      "| **ICE ì•„ë©”ë¦¬ì¹´ë…¸** | ì—ìŠ¤í”„ë ˆì†Œ + ì‹œì›í•œ ë¬¼ + ì–¼ìŒ |\n",
      "\n",
      "---\n",
      "\n",
      "### ğŸ’° **ê°€ê²© (2025ë…„ ê¸°ì¤€, ì„œìš¸ ê¸°ì¤€)**\n",
      "| ë¸Œëœë“œ | Hot/Ice | ê°€ê²© |\n",
      "|--------|----------|--------|\n",
      "| **ìŠ¤íƒ€ë²…ìŠ¤** | Tall ì‚¬ì´ì¦ˆ | â‚©4,600 |\n",
      "| **ë©”ê°€ì»¤í”¼** | ê¸°ë³¸ | â‚©1,500 |\n",
      "| **ì»¤í”¼ë¹ˆ** | Tall | â‚©4,100 |\n",
      "| **í• ë¦¬ìŠ¤** | Tall | â‚©4,200 |\n",
      "| **ì´ë””ì•¼** | ê¸°ë³¸ | â‚©3,500 |\n",
      "| **ì»¤í”¼ ì „ë¬¸ì (ì¼ë°˜)** | â€“ | â‚©2,000~â‚©4,500 |\n",
      "\n",
      "---\n",
      "\n",
      "### ğŸ” ìš”ì•½\n",
      "- **ê°€ì¥ ë‹¨ìˆœí•˜ë©´ì„œë„ ê¹”ë”í•œ ì»¤í”¼**\n",
      "- **ì¹¼ë¡œë¦¬ ê±±ì • ì—†ì´ ì¹´í˜ì¸ ì„­ì·¨ ê°€ëŠ¥**\n",
      "- **ê°€ê²©ì€ ë¸Œëœë“œì— ë”°ë¼ 1,500ì›~4,600ì›ìœ¼ë¡œ í° ì°¨ì´**\n",
      "\n",
      "ê¶ê¸ˆí•œ ë¸Œëœë“œë‚˜ ë©”ë‰´ê°€ ë” ìˆë‹¤ë©´ ë§ì”€í•´ ì£¼ì„¸ìš”.\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------------------------------------------------\n",
    "# 2) ë„êµ¬ ì •ì˜ (tavily / wikipedia / local-db search)\n",
    "# ----------------------------------------------------------------------\n",
    "# a) Tavily (ì›¹ ìµœì‹  ê²€ìƒ‰) â€” LangChainì˜ TavilySearchResults íˆ´\n",
    "tavily_search_func = TavilySearchResults(max_results=2, name=\"tavily_search\")\n",
    "\n",
    "# b) Wikipedia ìš”ì•½\n",
    "@tool\n",
    "def wiki_summary(query: str) -> str:\n",
    "    \"\"\"ìœ„í‚¤í”¼ë””ì•„ì—ì„œ ì¼ë°˜ ì§€ì‹ì„ ê²€ìƒ‰/ìš”ì•½í•©ë‹ˆë‹¤.\"\"\"\n",
    "    wikipedia = WikipediaAPIWrapper(lang=\"ko\", top_k_results=1, doc_content_chars_max=2000)\n",
    "    try:\n",
    "        return wikipedia.run(query)\n",
    "    except Exception:\n",
    "        return f\"ìœ„í‚¤ì—ì„œ '{query}' ì •ë³´ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.\"\n",
    "\n",
    "# c) ë¡œì»¬ ì¹´í˜ ë©”ë‰´ DB ê²€ìƒ‰\n",
    "@tool\n",
    "def db_search_cafe_func(query: str) -> str:\n",
    "    \"\"\"ë¡œì»¬ ì¹´í˜ ë©”ë‰´ DBì—ì„œ ê°€ê²©/ì¬ë£Œ/ì„¤ëª… ê´€ë ¨ ì •ë³´ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.\"\"\"\n",
    "    vector_db = FAISS.load_local(str(DB_PATH), embeddings, allow_dangerous_deserialization=True)\n",
    "    retriever = vector_db.as_retriever(search_kwargs={\"k\": 2})\n",
    "    # ìµœì‹  APIëŠ” invoke ê¶Œì¥\n",
    "    results = retriever.invoke(query)\n",
    "    if not results:\n",
    "        return \"ê´€ë ¨ ë©”ë‰´ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\"\n",
    "    lines = []\n",
    "    for d in results:\n",
    "        lines.append(d.page_content.replace(\"\\n\", \" \"))\n",
    "    return \"ë©”ë‰´ ê²€ìƒ‰ ê²°ê³¼:\\n\" + \"\\n\".join(lines)\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 3) LLM + íˆ´ ë°”ì¸ë”© & ì²´ì¸ ì‹¤í–‰\n",
    "# ----------------------------------------------------------------------\n",
    "tools = [tavily_search_func, wiki_summary, db_search_cafe_func]\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    base_url=\"https://api.groq.com/openai/v1\",\n",
    "    model=\"moonshotai/kimi-k2-instruct-0905\",\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "def run_tool_chain(user_input: str) -> str:\n",
    "    # 1ì°¨ í˜¸ì¶œ: ì–´ë–¤ íˆ´ì„ ì“¸ì§€ LLMì´ ê²°ì •\n",
    "    first = llm.invoke([HumanMessage(content=user_input)])\n",
    "\n",
    "    # íˆ´ í˜¸ì¶œì´ ì—†ìœ¼ë©´ ë°”ë¡œ ë‹µë³€\n",
    "    if not isinstance(first, AIMessage) or not getattr(first, \"tool_calls\", None):\n",
    "        return first.content\n",
    "\n",
    "    tool_msgs: List[ToolMessage] = []\n",
    "    print(\"\\n--- LLM tool_calls ---\")\n",
    "    pprint(first.tool_calls)\n",
    "\n",
    "    # ê° íˆ´ ì‹¤í–‰\n",
    "    for call in first.tool_calls:\n",
    "        name: str = call[\"name\"]\n",
    "        tool_id: str = call[\"id\"]\n",
    "        args: Any = call.get(\"args\", {})\n",
    "\n",
    "        # argsê°€ strë¡œ ì˜¤ëŠ” ëª¨ë¸ë„ ìˆì–´ ì•ˆì „ ì²˜ë¦¬\n",
    "        if isinstance(args, str):\n",
    "            try:\n",
    "                args = json.loads(args)\n",
    "            except json.JSONDecodeError:\n",
    "                args = {}\n",
    "\n",
    "        # ê³µí†µì ìœ¼ë¡œ 'query' í‚¤ ì‚¬ìš©\n",
    "        if name == \"tavily_search\":\n",
    "            out = tavily_search_func.invoke(args.get(\"query\", user_input))\n",
    "        elif name == \"wiki_summary\":\n",
    "            out = wiki_summary.invoke(args.get(\"query\", user_input))\n",
    "        elif name == \"db_search_cafe_func\":\n",
    "            out = db_search_cafe_func.invoke(args.get(\"query\", user_input))\n",
    "        else:\n",
    "            out = f\"ì•Œ ìˆ˜ ì—†ëŠ” ë„êµ¬: {name}\"\n",
    "\n",
    "        tool_msgs.append(ToolMessage(content=str(out), tool_call_id=tool_id))\n",
    "\n",
    "    # ë„êµ¬ ê²°ê³¼ë¥¼ ë‹¤ì‹œ LLMì— ì „ë‹¬í•´ ìµœì¢… ë‹µë³€ ìƒì„±\n",
    "    final = llm.invoke([HumanMessage(content=user_input), first, *tool_msgs])\n",
    "    return final.content\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 4) í…ŒìŠ¤íŠ¸\n",
    "# ----------------------------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    q = \"ì•„ë©”ë¦¬ì¹´ë…¸ì˜ ê°€ê²©ê³¼ íŠ¹ì§•ì€ ë¬´ì—‡ì¸ê°€ìš”?\"\n",
    "    ans = run_tool_chain(q)\n",
    "    print(f\"\\n[ì§ˆë¬¸] {q}\")\n",
    "    print(f\"[ë‹µë³€] {ans}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mylangchain-app-auRXAaAq-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
