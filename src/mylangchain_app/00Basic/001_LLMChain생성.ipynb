{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed0f96f1-910f-438f-876f-9eff119c2b0a",
   "metadata": {
    "id": "ed0f96f1-910f-438f-876f-9eff119c2b0a"
   },
   "source": [
    "### LLM Chain 만들기\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5b1e2f-9d67-4d01-9a8c-83ced6b711a9",
   "metadata": {
    "id": "5a5b1e2f-9d67-4d01-9a8c-83ced6b711a9"
   },
   "source": [
    "## 1. 환경 구성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03b7854-f96a-47fc-b3c7-b2bdfb55df81",
   "metadata": {
    "id": "b03b7854-f96a-47fc-b3c7-b2bdfb55df81"
   },
   "source": [
    "### 1) 라이브러리 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4cd87a33-0a37-461b-8f37-3c142e60b1f6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4cd87a33-0a37-461b-8f37-3c142e60b1f6",
    "outputId": "c96ed02d-19b7-4e90-d92e-1ae52895e303"
   },
   "outputs": [],
   "source": [
    "# poetry add python-dotenv langchain langchain-openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55152049-e9e5-4952-8e19-409f58cf3ac9",
   "metadata": {
    "id": "55152049-e9e5-4952-8e19-409f58cf3ac9"
   },
   "source": [
    "### 2) OpenAI 인증키 설정\n",
    "https://openai.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b76f68a8-4745-4377-8057-6090b87377d1",
   "metadata": {
    "id": "b76f68a8-4745-4377-8057-6090b87377d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gsk_4\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "# .env 파일을 불러와서 환경 변수로 설정\n",
    "load_dotenv(dotenv_path='.env')\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "print(OPENAI_API_KEY[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e09aaca6-5aa2-4b52-bbfc-196e808dc5cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3.27\n"
     ]
    }
   ],
   "source": [
    "import langchain\n",
    "print(langchain.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc01c50a-32cf-49af-891a-f9b17fa0bd6c",
   "metadata": {
    "id": "fc01c50a-32cf-49af-891a-f9b17fa0bd6c"
   },
   "source": [
    "## 2. LLM Chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23729d10-9600-415b-b7d1-f954665224e3",
   "metadata": {
    "id": "23729d10-9600-415b-b7d1-f954665224e3"
   },
   "source": [
    "### 1) Prompt + LLM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "on0y4xF8VoyE",
   "metadata": {
    "id": "on0y4xF8VoyE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.messages.ai.AIMessage'>\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# model\n",
    "# llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "llm = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",  # Spring AI와 동일한 모델\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "# chain 실행\n",
    "result = llm.invoke(\"인공지능 모델의 학습 원리에 대하여 쉽게 설명해 주세요.\")\n",
    "print(type(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4dc4accf-c927-40a3-ba2c-f891c94c34f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='인공지능 모델의 학습 원리는 다음과 같습니다.\\n\\n1.  **데이터 수집**: 인공지능 모델은 대량의 데이터를 수집합니다. 이 데이터는 모델이 학습하고 예측을 수행하는 데 사용됩니다.\\n2.  **데이터 전처리**: 수집된 데이터는 전처리 과정을 거칩니다. 이 과정에서는 데이터를 정제하고, 필요한 경우 데이터를 변환하거나 보완합니다.\\n3.  **모델 정의**: 인공지능 모델은 수학적 알고리즘과 통계적 기법을 사용하여 정의됩니다. 이 모델은 입력 데이터를 받아서 출력 데이터를 생성합니다.\\n4.  **학습**: 모델은 수집된 데이터를 사용하여 학습합니다. 이 과정에서는 모델이 데이터를 분석하고, 패턴을 발견하며, 예측을 수행하는 데 필요한 가중치를 조정합니다.\\n5.  **평가**: 학습이 완료된 후, 모델은 평가 데이터에 대해 평가됩니다. 이 과정에서는 모델의 성능을 측정하고, 모델이 얼마나 정확하게 예측을 수행하는지 확인합니다.\\n6.  **최적화**: 평가 결과에 따라 모델을 최적화합니다. 이 과정에서는 모델의 가중치를 조정하여 성능을 향상시킵니다.\\n\\n예를 들어, 이미지 분류 모델을 학습하는 경우를 생각해 봅시다.\\n\\n*   **데이터 수집**: 다양한 이미지를 수집합니다. 이 이미지에는 고양이, 강아지, 자동차 등 다양한 객체가 포함됩니다.\\n*   **데이터 전처리**: 이미지를 정제하고, 크기를 조정하며, 필요한 경우 이미지를 변환합니다.\\n*   **모델 정의**: 이미지 분류 모델을 정의합니다. 이 모델은 이미지를 입력으로 받아서 객체를 분류합니다.\\n*   **학습**: 모델은 수집된 이미지를 사용하여 학습합니다. 이 과정에서는 모델이 이미지를 분석하고, 객체를 분류하는 데 필요한 가중치를 조정합니다.\\n*   **평가**: 학습이 완료된 후, 모델은 평가 데이터에 대해 평가합니다. 이 과정에서는 모델의 성능을 측정하고, 모델이 얼마나 정확하게 객체를 분류하는지 확인합니다.\\n*   **최적화**: 평가 결과에 따라 모델을 최적화합니다. 이 과정에서는 모델의 가중치를 조정하여 성능을 향상시킵니다.\\n\\n인공지능 모델의 학습 원리는 데이터 수집, 데이터 전처리, 모델 정의, 학습, 평가, 최적화의 과정을 포함합니다. 이 과정을 통해 모델은 데이터를 분석하고, 패턴을 발견하며, 예측을 수행하는 능력을 향상시킬 수 있습니다.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 498, 'prompt_tokens': 24, 'total_tokens': 522, 'completion_tokens_details': None, 'prompt_tokens_details': None, 'queue_time': 0.364312158, 'prompt_time': 0.000535069, 'completion_time': 1.238576837, 'total_time': 1.239111906}, 'model_name': 'meta-llama/llama-4-scout-17b-16e-instruct', 'system_fingerprint': 'fp_5d3e4e58e1', 'id': 'chatcmpl-bdbce86e-6697-4c09-9e49-67aff99e32d3', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None} id='run--ec44c0f6-946b-44e3-9d2a-f8e4852cb290-0' usage_metadata={'input_tokens': 24, 'output_tokens': 498, 'total_tokens': 522, 'input_token_details': {}, 'output_token_details': {}}\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "WzcZy4PruV1n",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "id": "WzcZy4PruV1n",
    "outputId": "18ecc8f9-5748-4b16-cb07-4a0f7a01fb5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인공지능 모델의 학습 원리는 다음과 같습니다.\n",
      "\n",
      "1.  **데이터 수집**: 인공지능 모델은 대량의 데이터를 수집합니다. 이 데이터는 모델이 학습하고 예측을 수행하는 데 사용됩니다.\n",
      "2.  **데이터 전처리**: 수집된 데이터는 전처리 과정을 거칩니다. 이 과정에서는 데이터를 정제하고, 필요한 경우 데이터를 변환하거나 보완합니다.\n",
      "3.  **모델 정의**: 인공지능 모델은 수학적 알고리즘과 통계적 기법을 사용하여 정의됩니다. 이 모델은 입력 데이터를 받아서 출력 데이터를 생성합니다.\n",
      "4.  **학습**: 모델은 수집된 데이터를 사용하여 학습합니다. 이 과정에서는 모델이 데이터를 분석하고, 패턴을 발견하며, 예측을 수행하는 데 필요한 가중치를 조정합니다.\n",
      "5.  **평가**: 학습이 완료된 후, 모델은 평가 데이터에 대해 평가됩니다. 이 과정에서는 모델의 성능을 측정하고, 모델이 얼마나 정확하게 예측을 수행하는지 확인합니다.\n",
      "6.  **최적화**: 평가 결과에 따라 모델을 최적화합니다. 이 과정에서는 모델의 가중치를 조정하여 성능을 향상시킵니다.\n",
      "\n",
      "예를 들어, 이미지 분류 모델을 학습하는 경우를 생각해 봅시다.\n",
      "\n",
      "*   **데이터 수집**: 다양한 이미지를 수집합니다. 이 이미지에는 고양이, 강아지, 자동차 등 다양한 객체가 포함됩니다.\n",
      "*   **데이터 전처리**: 이미지를 정제하고, 크기를 조정하며, 필요한 경우 이미지를 변환합니다.\n",
      "*   **모델 정의**: 이미지 분류 모델을 정의합니다. 이 모델은 이미지를 입력으로 받아서 객체를 분류합니다.\n",
      "*   **학습**: 모델은 수집된 이미지를 사용하여 학습합니다. 이 과정에서는 모델이 이미지를 분석하고, 객체를 분류하는 데 필요한 가중치를 조정합니다.\n",
      "*   **평가**: 학습이 완료된 후, 모델은 평가 데이터에 대해 평가합니다. 이 과정에서는 모델의 성능을 측정하고, 모델이 얼마나 정확하게 객체를 분류하는지 확인합니다.\n",
      "*   **최적화**: 평가 결과에 따라 모델을 최적화합니다. 이 과정에서는 모델의 가중치를 조정하여 성능을 향상시킵니다.\n",
      "\n",
      "인공지능 모델의 학습 원리는 데이터 수집, 데이터 전처리, 모델 정의, 학습, 평가, 최적화의 과정을 포함합니다. 이 과정을 통해 모델은 데이터를 분석하고, 패턴을 발견하며, 예측을 수행하는 능력을 향상시킬 수 있습니다.\n"
     ]
    }
   ],
   "source": [
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5c97fc",
   "metadata": {},
   "source": [
    "### 2) PromptTemplate + LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "SeNi_VXqYD-b",
   "metadata": {
    "id": "SeNi_VXqYD-b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.prompts.prompt.PromptTemplate'>\n",
      "input_variables=['input'] input_types={} partial_variables={} template='You are an expert in AI Expert. Answer the question. <Question>: {input}에 대해 쉽게 설명해주세요.'\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"You are an expert in AI Expert. Answer the question. <Question>: {input}에 대해 쉽게 설명해주세요.\")\n",
    "\n",
    "print(type(prompt))\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01WLucSpYjZt",
   "metadata": {
    "id": "01WLucSpYjZt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.runnables.base.RunnableSequence'>\n",
      "<class 'langchain_core.messages.ai.AIMessage'>\n",
      "content='인공지능 모델의 학습 원리는 사람의 뇌가 학습하는 원리와 유사합니다. \\n\\n사람이 경험을 통해 학습하듯이, 인공지능 모델도 데이터를 통해 학습합니다. \\n\\n예를 들어, 고양이를 인식하는 모델을 개발한다고 가정해 봅시다. \\n\\n이를 위해 인터넷에서 고양이 사진 100만 장을 수집했다고 가정해 봅시다. \\n\\n이 사진들을 모델에 보여주면서, \"이것은 고양이\"라는 라벨을 달아주는 겁니다. \\n\\n그러면 모델은 이 사진들을 분석해서 고양이의 특징을 스스로 학습합니다. \\n\\n고양이는 털이 많고, 귀가 있고, 눈이 두 개라는 등의 특징을 스스로 발견하는 거죠. \\n\\n이렇게 학습한 모델은 새로운 사진을 보여주었을 때, 고양이인지 아닌지 스스로 판별할 수 있습니다.\\n\\n이러한 학습 과정을 수학적으로 표현하면, 최적화 문제로 귀결됩니다. \\n\\n즉, 모델의 성능을 나타내는 손실 함수를 정의하고, 이 손실 함수를 최소화하는 방향으로 모델의 파라미터를 업데이트하는 겁니다. \\n\\n이를 위해 경사 하강법이라는 최적화 알고리즘을 사용합니다. \\n\\n경사 하강법은 손실 함수의 기울기를 계산하고, 이 기울기의 반대 방향으로 모델의 파라미터를 업데이트하는 알고리즘입니다.\\n\\n모델의 학습 과정은 다음과 같습니다.\\n\\n1. 데이터 수집: 학습에 필요한 데이터를 수집합니다.\\n2. 데이터 전처리: 수집한 데이터를 모델이 학습할 수 있도록 전처리합니다.\\n3. 모델 정의: 학습할 모델을 정의합니다.\\n4. 손실 함수 정의: 모델의 성능을 나타내는 손실 함수를 정의합니다.\\n5. 최적화 알고리즘 선택: 모델의 파라미터를 업데이트할 최적화 알고리즘을 선택합니다.\\n6. 학습: 모델을 학습합니다.\\n7. 평가: 학습한 모델의 성능을 평가합니다.\\n\\n이렇게 학습한 모델은 새로운 데이터에 대해 예측을 수행할 수 있습니다. \\n\\n예를 들어, 고양이 인식 모델은 새로운 사진을 보여주었을 때, 고양이인지 아닌지 예측할 수 있습니다.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 424, 'prompt_tokens': 36, 'total_tokens': 460, 'completion_tokens_details': None, 'prompt_tokens_details': None, 'queue_time': 0.201940823, 'prompt_time': 0.00052262, 'completion_time': 0.988232303, 'total_time': 0.988754923}, 'model_name': 'meta-llama/llama-4-scout-17b-16e-instruct', 'system_fingerprint': 'fp_5d3e4e58e1', 'id': 'chatcmpl-9a81383a-6525-42c0-9a8f-15165a55ae4a', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None} id='run--226adde7-146d-43c7-ac09-beb474697a07-0' usage_metadata={'input_tokens': 36, 'output_tokens': 424, 'total_tokens': 460, 'input_token_details': {}, 'output_token_details': {}}\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "llm = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",  # Spring AI와 동일한 모델\n",
    "    temperature=0.7\n",
    ")\n",
    "# chain 연결 (LCEL)\n",
    "chain = prompt | llm\n",
    "print(type(chain))\n",
    "\n",
    "# chain 호출\n",
    "result = chain.invoke({\"input\": \"인공지능 모델의 학습 원리\"})\n",
    "print(type(result))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "170ec878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인공지능 모델의 학습 원리는 사람의 뇌가 학습하는 원리와 유사합니다. \n",
      "\n",
      "사람이 경험을 통해 학습하듯이, 인공지능 모델도 데이터를 통해 학습합니다. \n",
      "\n",
      "예를 들어, 고양이를 인식하는 모델을 개발한다고 가정해 봅시다. \n",
      "\n",
      "이를 위해 인터넷에서 고양이 사진 100만 장을 수집했다고 가정해 봅시다. \n",
      "\n",
      "이 사진들을 모델에 보여주면서, \"이것은 고양이\"라는 라벨을 달아주는 겁니다. \n",
      "\n",
      "그러면 모델은 이 사진들을 분석해서 고양이의 특징을 스스로 학습합니다. \n",
      "\n",
      "고양이는 털이 많고, 귀가 있고, 눈이 두 개라는 등의 특징을 스스로 발견하는 거죠. \n",
      "\n",
      "이렇게 학습한 모델은 새로운 사진을 보여주었을 때, 고양이인지 아닌지 스스로 판별할 수 있습니다.\n",
      "\n",
      "이러한 학습 과정을 수학적으로 표현하면, 최적화 문제로 귀결됩니다. \n",
      "\n",
      "즉, 모델의 성능을 나타내는 손실 함수를 정의하고, 이 손실 함수를 최소화하는 방향으로 모델의 파라미터를 업데이트하는 겁니다. \n",
      "\n",
      "이를 위해 경사 하강법이라는 최적화 알고리즘을 사용합니다. \n",
      "\n",
      "경사 하강법은 손실 함수의 기울기를 계산하고, 이 기울기의 반대 방향으로 모델의 파라미터를 업데이트하는 알고리즘입니다.\n",
      "\n",
      "모델의 학습 과정은 다음과 같습니다.\n",
      "\n",
      "1. 데이터 수집: 학습에 필요한 데이터를 수집합니다.\n",
      "2. 데이터 전처리: 수집한 데이터를 모델이 학습할 수 있도록 전처리합니다.\n",
      "3. 모델 정의: 학습할 모델을 정의합니다.\n",
      "4. 손실 함수 정의: 모델의 성능을 나타내는 손실 함수를 정의합니다.\n",
      "5. 최적화 알고리즘 선택: 모델의 파라미터를 업데이트할 최적화 알고리즘을 선택합니다.\n",
      "6. 학습: 모델을 학습합니다.\n",
      "7. 평가: 학습한 모델의 성능을 평가합니다.\n",
      "\n",
      "이렇게 학습한 모델은 새로운 데이터에 대해 예측을 수행할 수 있습니다. \n",
      "\n",
      "예를 들어, 고양이 인식 모델은 새로운 사진을 보여주었을 때, 고양이인지 아닌지 예측할 수 있습니다.\n"
     ]
    }
   ],
   "source": [
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56848a4c",
   "metadata": {},
   "source": [
    "### 3) PromptTemplate + LLM(invoke()) + StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d1e9009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.runnables.base.RunnableSequence'>\n",
      "<class 'str'>\n",
      "인공지능 모델의 학습 원리는 사람의 뇌가 학습하는 방식과 유사합니다. 컴퓨터가 데이터를 통해 배우고, 데이터를 기반으로 예측이나 판단을 내리는 과정을 거칩니다. 이는 크게 세 가지 단계로 설명할 수 있습니다: 데이터 수집, 모델 훈련, 그리고 예측 또는 평가입니다.\n",
      "\n",
      "1. **데이터 수집**: 인공지능 모델이 학습하기 위해서는 많은 양의 데이터가 필요합니다. 이 데이터는 과거의 경험에서 얻어진 정보일 수 있으며, 이미지, 텍스트, 오디오 등 다양한 형태가 될 수 있습니다.\n",
      "\n",
      "2. **모델 훈련**: 수집된 데이터를 바탕으로 모델을 훈련시킵니다. 이 과정에서는 모델이 데이터를 분석하고, 데이터 속에 있는 패턴이나 관계를 발견하려고 합니다. 예를 들어, 이미지 인식 모델을 만든다고 가정해 봅시다. 이 모델은 수많은 고양이와 강개의 사진을 통해 고양이와 강개를 구별하는 법을 배웁니다.\n",
      "\n",
      "3. **예측 또는 평가**: 모델이 훈련된 후, 새로운 데이터를 받았을 때, 학습한 패턴을 바탕으로 예측이나 판단을 합니다. 예를 들어, 새로운 이미지가 주어졌을 때, 이 모델은 그것이 고양이인지 강개인지 구별할 수 있습니다.\n",
      "\n",
      "이러한 학습 과정은 여러 알고리즘을 통해 이루어지며, 그중 가장 기본적인 알고리즘은 아래와 같습니다:\n",
      "\n",
      "- **지도 학습(Supervised Learning)**: 모델이 이미 레이블이 지정된 데이터를 통해 학습하는 방식입니다. 예를 들어, 사진과 그에 따른 설명(레이블)이 주어진 경우, 모델은 사진을 보고 설명을 예측하도록 학습합니다.\n",
      "\n",
      "- **비지도 학습(Unsupervised Learning)**: 모델이 레이블이 없는 데이터를 분석하여 패턴이나 관계를 스스로 찾는 방식입니다. 주로 데이터의 구조를 파악하거나 그룹화를 할 때 사용됩니다.\n",
      "\n",
      "- **강화 학습(Reinforcement Learning)**: 모델이 환경과 상호작용하며 보상을 최대화하는 방향으로 학습하는 방식입니다. 이 경우, 모델은 시행착오를 통해 최적의 행동을 학습합니다.\n",
      "\n",
      "이렇게 인공지능 모델은 주어진 데이터를 통해 지속적으로 학습하고, 이를 바탕으로 더 나은 예측과 판단을 내릴 수 있게 됩니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# 1. 컴포넌트 정의\n",
    "prompt = PromptTemplate.from_template(\"You are an expert in AI Expert. \\\n",
    "                                      Answer the question. <Question>: {input}에 대해 쉽게 설명해주세요.\")\n",
    "\n",
    "# llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "llm = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",  # Spring AI와 동일한 모델\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "# 2. chain 생성 (LCEL)\n",
    "chain = prompt | llm | output_parser\n",
    "print(type(chain))\n",
    "\n",
    "# 3. chain의 invoke 호출\n",
    "result = chain.invoke({\"input\": \"인공지능 모델의 학습 원리\"})\n",
    "print(type(result))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d997b16",
   "metadata": {},
   "source": [
    "### 4) PromptTemplate + LLM(stream()) + StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "684654e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인공지능 모델의 학습 원리는 사람의 뇌가 학습하는 원리와 유사합니다. \n",
      "\n",
      "기본적으로 인공지능 모델은 데이터를 통해 학습합니다. 예를 들어, 고양이와 강아지의 사진을 분류하는 모델을 만든다고 가정해 봅시다. \n",
      "\n",
      "1. **데이터 수집**: 수많은 고양이와 강아지의 사진을 수집합니다.\n",
      "2. **데이터 전처리**: 수집한 사진들을 컴퓨터가 처리할 수 있는 형태로 변환합니다.\n",
      "3. **모델 초기화**: 모델을 초기화합니다. 이 모델은 고양이와 강아지 사진을 구분할 수 있는 신경망 구조로 되어 있습니다.\n",
      "4. **학습 과정**: \n",
      "   - 모델에 고양이 사진과 강아지 사진을 하나씩 보여줍니다.\n",
      "   - 모델은 사진의 특징을 추출하고, 이것이 고양이인지 강아지인지를 예측합니다.\n",
      "   - 예측 결과와 실제 사진의 라벨(고양이 또는 강아지)을 비교하여 오류를 계산합니다.\n",
      "   - 모델은 오류를 줄이기 위해 자동으로 내부 파라미터(가중치와 편향)를 조정합니다. 이 과정은 역전파(backpropagation) 알고리즘을 통해 이루어집니다.\n",
      "5. **반복 학습**: 이 과정을 수많은 사진들에 대해 반복합니다. 모델은 매번 조금씩 더 정확해집니다.\n",
      "6. **성능 평가**: 일정 횟수 학습시킨 후, 별도의 테스트 데이터를 사용하여 모델의 성능을 평가합니다.\n",
      "\n",
      "이처럼 인공지능 모델은 주어진 데이터를 통해 지속적으로 학습하고, 그 과정에서 스스로 규칙과 패턴을 발견하여 예측 능력을 향상시킵니다. 이 학습 원리는 다양한 머신러닝과 딥러닝 알고리즘에서 기본이 되는 개념입니다."
     ]
    }
   ],
   "source": [
    "\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# 1. 컴포넌트 정의\n",
    "prompt = PromptTemplate.from_template(\"You are an expert in AI Expert. \\\n",
    "                                      Answer the question. <Question>: {input}에 대해 쉽게 설명해주세요.\")\n",
    "\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "lm = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",  # Spring AI와 동일한 모델\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "# chain 연결 (LCEL)\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "# 스트리밍 출력을 위한 요청\n",
    "answer = chain.stream({\"input\": \"인공지능 모델의 학습 원리\"})\n",
    "# 스트리밍 출력\n",
    "#print(answer)\n",
    "\n",
    "for token in answer:\n",
    "    # 스트림에서 받은 데이터의 내용을 출력합니다. 줄바꿈 없이 이어서 출력하고, 버퍼를 즉시 비웁니다.\n",
    "    print(token, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0188674-915f-41af-ac46-56f9f54289b0",
   "metadata": {
    "id": "b0188674-915f-41af-ac46-56f9f54289b0"
   },
   "source": [
    "##### 2) Multiple Chains\n",
    "* Multi Chain을 활용한 영화 추천 및 줄거리 요약 ( 잘 동작하지 않는 코드)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31678c55-38a8-4ca2-b437-9d4495946b0a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "31678c55-38a8-4ca2-b437-9d4495946b0a",
    "outputId": "7ee83878-5d1a-45e3-f033-100da33f3ee9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      " ===> 추천된 영화:\n",
      "**『쇼생크 탈출(The Shawshank Redemption)』**  \n",
      "1994년, 프랭크 다라본트 감독  \n",
      "\n",
      "감옥이라는 극한의 공간에서도 희망을 빼앗기지 않는 한 남자의 20년 간 인내와 우정, 그리고 ‘자유’에 대한 이야기입니다. 사회의 부조리와 인간의 존엄성을 절묘하게 교차시키며, 마지막 10분만으로도 평생 뇌리에 남는 여운을 선사합니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Step 1: 사용자가 입력한 장르에 따라 영화 추천\n",
    "prompt1 = ChatPromptTemplate.from_template(\"{genre} 장르에서 추천할 만한 영화를 한 편 알려주세요.\")\n",
    "\n",
    "# Step 2: 추천된 영화의 줄거리를 요약\n",
    "prompt2 = ChatPromptTemplate.from_template(\"{movie} 추천한 영화의 제목을 먼저 알려주시고, 줄을 바꾸어서 영화의 정보(제목,감독,캐스팅,줄거리)를 알려 주세요\")\n",
    "\n",
    "# OpenAI 모델 사용\n",
    "# llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "llm = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    #model=\"meta-llama/llama-4-scout-17b-16e-instruct\",  # Spring AI와 동일한 모델\n",
    "    model=\"moonshotai/kimi-k2-instruct-0905\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "# 체인 1: 영화 추천 (입력: 장르 → 출력: 영화 제목)\n",
    "chain1 = prompt1 | llm | StrOutputParser()\n",
    "\n",
    "# Step 1: 사용자가 입력한 장르에 따라 영화 추천\n",
    "movie = chain1.invoke({\"genre\": \"Drama\"})  # 영화 제목 얻기\n",
    "\n",
    "print(type(movie))\n",
    "print(\" ===> 추천된 영화:\")  # movie 값 출력\n",
    "print(movie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "16718b76-f59d-48f7-906f-5d2371417803",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "16718b76-f59d-48f7-906f-5d2371417803",
    "outputId": "6e3371cd-d294-4be7-a868-2eae5ee6e5de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first={\n",
      "  movie: ChatPromptTemplate(input_variables=['genre'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['genre'], input_types={}, partial_variables={}, template='{genre} 장르에서 추천할 만한 영화를 한 편 알려주세요.'), additional_kwargs={})])\n",
      "         | ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000001721E04BBF0>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x000001721E017F20>, root_client=<openai.OpenAI object at 0x000001721E017770>, root_async_client=<openai.AsyncOpenAI object at 0x000001721DE82F30>, model_name='moonshotai/kimi-k2-instruct-0905', temperature=0.7, model_kwargs={}, openai_api_key=SecretStr('**********'), openai_api_base='https://api.groq.com/openai/v1')\n",
      "         | StrOutputParser()\n",
      "} middle=[ChatPromptTemplate(input_variables=['movie'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['movie'], input_types={}, partial_variables={}, template='{movie} 추천한 영화의 제목을 먼저 알려주시고, 줄을 바꾸어서 영화의 정보(제목,감독,캐스팅,줄거리)를 알려 주세요'), additional_kwargs={})]), ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000001721E04BBF0>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x000001721E017F20>, root_client=<openai.OpenAI object at 0x000001721E017770>, root_async_client=<openai.AsyncOpenAI object at 0x000001721DE82F30>, model_name='moonshotai/kimi-k2-instruct-0905', temperature=0.7, model_kwargs={}, openai_api_key=SecretStr('**********'), openai_api_base='https://api.groq.com/openai/v1')] last=StrOutputParser()\n",
      "\n",
      "🔹 영화 줄거리 요약:\n",
      " **버닝**\n",
      "\n",
      "제목: 버닝 (Burning, 2018)  \n",
      "감독: 이창동  \n",
      "캐스팅: 유아인(종수), 스티븐 연(베니), 전종서(하미)  \n",
      "줄거리: 배달원 종수는 어릴 지인 하미를 만나 사이가 가까워지지만, 하미는 아프리카 여행 중 우연히 만난 신비로운 부호 베니를 소개한다. 둘은 돌아온 뒤 베니의 고급 아파트에서 종종 만나며 위태로운 삼각관계를 이어가던 중, 하미가 갑작스레 연락을 끊고 사라진다. 빈곤과 계층의 벽, 억눌린 분노를 품은 종수는 그녀의 실종 뒤에 베니가 있다고 의심하며 추적하지만, 진실은 점점 더 안개 속으로 빠져든다.\n"
     ]
    }
   ],
   "source": [
    "# 체인 2: 줄거리 요약 (입력: 영화 제목 → 출력: 줄거리)\n",
    "chain2 = (\n",
    "    {\"movie\": chain1}  # chain1의 출력을 movie 변수로 전달\n",
    "    | prompt2\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "print(chain2)\n",
    "\n",
    "# 실행: \"SF\" 장르의 영화 추천 및 줄거리 요약\n",
    "response = chain2.invoke({\"genre\": \"Drama\"})\n",
    "print(\"\\n🔹 영화 줄거리 요약:\\n\", response) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb684fd",
   "metadata": {},
   "source": [
    "##### chain1과 chain2에서 영화 제목이 일관되게 전달 되도록 변경 ( 잘 동작하는 코드)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e30883ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔹 영화 줄거리 요약:\n",
      "('쇼생크 탈출\\n'\n",
      " '\\n'\n",
      " '쇼생크 탈출  \\n'\n",
      " '감독: 프랭크 다라본트  \\n'\n",
      " '출연: 팀 로빈스(앤디 듀프레인), 모건 프리먼(레드)\\n'\n",
      " '\\n'\n",
      " '1947년, 아내와 그녀의 정부를 살해했다는 누명을 쓴 은행원 앤디는 쇼생크 교도소에 무기징역으로 수감된다.  \\n'\n",
      " '차분하고 지적인 그는 교도소 내에서도 희망을 잃지 않고, 동료 죄수 레드와 깊은 우정을 쌓는다.  \\n'\n",
      " '20여 년에 걸쳐 교도소 관리들의 세탁·탈세를 도와주며 특별한 신뢰를 얻던 앤디는 어느 날 박사처럼 증발—그리고 마침내 진짜 ‘탈출’을 '\n",
      " '실행한다.  \\n'\n",
      " '빗줄기 속에서 맞이한 자유, 그리고 레드가 약속대로 그를 찾아가며 두 사람은 태평양의 푸른 바다 앞에서 다시 만난다.')\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "# Step 1: 사용자가 입력한 장르에 따라 영화 추천\n",
    "prompt1 = ChatPromptTemplate.from_template(\"{genre} 장르에서 추천할 만한 영화를 한 편 알려주세요.\")\n",
    "\n",
    "# Step 2: 추천된 영화의 줄거리를 요약\n",
    "prompt2 = ChatPromptTemplate.from_template(\"{movie} 추천한 영화의 제목을 먼저 알려주시고, 줄을 바꾸어서 영화의 정보(제목,감독,캐스팅,줄거리)를 알려 주세요.\")\n",
    "\n",
    "# OpenAI 모델 사용\n",
    "llm = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    #model=\"meta-llama/llama-4-scout-17b-16e-instruct\",  # Spring AI와 동일한 모델\n",
    "    model=\"moonshotai/kimi-k2-instruct-0905\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "# 체인 1: 영화 추천 (입력: 장르 → 출력: 영화 제목)\n",
    "chain1 = prompt1 | llm | StrOutputParser()\n",
    "\n",
    "# 체인 2: 줄거리 요약 (입력: 영화 제목 → 출력: 줄거리)\n",
    "chain2 = (\n",
    "    {\"movie\": chain1}  # chain1의 출력을 movie 변수로 전달\n",
    "    | prompt2\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# 실행: \"Drama\" 장르의 영화 추천 및 줄거리 요약\n",
    "response = chain2.invoke({\"genre\": \"Drama\"})\n",
    "print(\"\\n🔹 영화 줄거리 요약:\")\n",
    "pprint(response)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "mylangchain-app-auRXAaAq-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
